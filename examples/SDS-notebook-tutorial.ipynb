{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "infectious-estimate",
   "metadata": {},
   "source": [
    "# Similarity Down-Selection -- Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedicated-bradford",
   "metadata": {},
   "source": [
    "Similarity Down-selection (SDS) heuristically finds the most dissimilar set of size `n`\n",
    "out of a population represented as an NxN matrix where the ith row (as well as the\n",
    "ith column) belong to item i, and the element (i,j) is some pairwise relation between \n",
    "items i and j. \n",
    "\n",
    "The pairwise relation is a floating point value where larger values indicate\n",
    "greater dissimilarity, and where the pairwise relation between item i and itself is represented\n",
    "as np.nan (this allows the program to work with numpy log conversion and sums).\n",
    "\n",
    "SDS was originally written to find the subset of n most dissimliar conformers \n",
    "(similarity being determined by average pairwise RMSD between atoms).\n",
    "In the original implemenation finding the n most dissimilar conformers \n",
    "for 50000x50000 matricies, SDS substationally outperformed a benchmark random sampling method in both \n",
    "time and accuracy. \n",
    "\n",
    "Note that because SDS finds the set of size `n` by building off of set `n-1`, finding set `n` also finds\n",
    "also previous set sizes from 2-n. \n",
    "\n",
    "\n",
    "\n",
    "Author: Felicity Nielson\n",
    "2019-2020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worse-brain",
   "metadata": {},
   "source": [
    "### To execute cells..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "federal-murder",
   "metadata": {},
   "source": [
    "Press `shift` + `enter` on mac osx.\n",
    "Press `esc` + `h` for more commands."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-height",
   "metadata": {},
   "source": [
    "### Alternatively..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-suspension",
   "metadata": {},
   "source": [
    "Run SDS from the command line using,\n",
    "\n",
    "`python sds.py -m <path to matrix file> -n <integer number of most dissimilar items to find> -b <True/False save benchmark info>`.\n",
    "\n",
    "For help information, execute `python sds.py -h`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "current-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import python libraries\n",
    "\n",
    "from time import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os.path import *\n",
    "import argparse\n",
    "import os\n",
    "from math import log"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "armed-neighbor",
   "metadata": {},
   "source": [
    "## Define the SDS function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "specialized-burning",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDS(df, n=3):\n",
    "    \"\"\"Finds the `n` most dissimilar items. In the input matrix, the ith row (and \n",
    "    ith column) is an array belonging to item i. The matrix element (i,j) would then be the pairwise \n",
    "    dissimilarity metric between items i and j (for example, geometric RMSD between molecular conformers i and j).\n",
    "\n",
    "    Args:\n",
    "      df (pandas.DataFrame): Square matrix where each row (and by symmetry, column) is an array \n",
    "                             corresponding to a specific item or object, and each element (i,j) the \n",
    "                             floating point dissimilarity between items i and j. The element (i,i) must\n",
    "                             be represented as np.nan (for log-summing).\n",
    "\n",
    "                             If pairwise data between two\n",
    "                             items is missing, this can also be represented as np.nan. What will\n",
    "                             happen is the second item will automatically be set to np.nan in the\n",
    "                             log-summation array once the first of one of the two items is chosen.\n",
    "                             Thus, the second item will never be chosen. In this same manner, \n",
    "                             entire missing items can be represented as arrays of np.nan, \n",
    "                             as a trick to preserve externally related indexing.\n",
    "\n",
    "      n (int): Dissimilar set size to find.\n",
    "               1 < n < N, where N is the full population size.\n",
    "    Returns:\n",
    "      pandas.DataFrame containing indices of the items found in the dissimilar set of size `n`. \n",
    "    \"\"\"\n",
    "    # Check df matrix is square.\n",
    "    N = len(df.index)\n",
    "    assert N == len(df.columns)\n",
    "    \n",
    "    # Reduce n to maximum number of items if n is over, otherwise the search will fail with an error.\n",
    "    M = len(df.dropna(how='all'))\n",
    "    if n > M:\n",
    "        n = M\n",
    "\n",
    "    print(f'Starting SDS search for most dissimilar set of size n = {n}...')\n",
    "\n",
    "    # First grab matrix indices of the two most dissimilar geometries.\n",
    "    row_mx = []\n",
    "    \n",
    "    for i in range(N):\n",
    "        row_mx.append(np.nanmax(df.loc[i]))\n",
    "    ind1 = np.nanargmax(row_mx)\n",
    "    ind2 = ind1 + 1 + np.nanargmax(row_mx[ind1+1:])\n",
    "\n",
    "    # Initialize the dissimilar matrix with the two most dissimilar\n",
    "    disarray = [np.array(df.loc[ind1]), np.array(df.loc[ind2])]\n",
    "    indices = [ind1, ind2]\n",
    "    \n",
    "    # Find n-2 other most dissimilar\n",
    "     # Multiply the rows of the n-1 dissimilar set. Or,\n",
    "     # use log summing if N is large (e.g. 50000) to avoid \n",
    "     # exceeding floating point machine precision.\n",
    "     # This script uses log summing.\n",
    "     # The index of the largest value is the index of the nth\n",
    "     # item which makes the nth dissimilar set.\n",
    "\n",
    "    # Initialize array for log summing\n",
    "    logsum = [0 for x in range(N)]\n",
    "    logsum += np.log(disarray[0])\n",
    "    \n",
    "    for i in range(n-2):\n",
    "        logsum += np.log(disarray[-1])\n",
    "        indn = np.nanargmax(logsum)\n",
    "        indices.append(indn)\n",
    "        disarray.append(np.array(df.loc[indn]))\n",
    "\n",
    "    return_df = pd.DataFrame([indices], index=['matrix index']).T\n",
    "\n",
    "    print('Finished')\n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-cutting",
   "metadata": {},
   "source": [
    "## Provide path to file containing the square matrix of floating point values which are the pairwise relationships (e.g. dissimilarity) between items represented by the rows and columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "average-circle",
   "metadata": {},
   "source": [
    "File extension can be either .pkl or .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seeing-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load from CSV file.\n",
    "df = pd.from_csv('your_path_to_file_here.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-mixer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, load from pickle file.\n",
    "df = pd.from_pickle('your_path_to_file_here.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "competent-internship",
   "metadata": {},
   "source": [
    "### Declare variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-provision",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the `n` most dissimilar items, integer.\n",
    "n = 3 # Change integer number here.\n",
    "\n",
    "# Benchmark, saves time and total dissimilarity data.\n",
    "b = True # Change bool here, i.e. True or False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "talented-truth",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get beginning timestamp.\n",
    "start = time()\n",
    "\n",
    "# If SDS is not already a directory, make it.\n",
    "directory = 'SDS'\n",
    "if not exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n",
    "# Run SDS\n",
    "SDSdf = SDS(df, n=n)\n",
    "\n",
    "# Create array of SDS values.\n",
    " # Because this algorithm builds off the previous set size, all set sizes `1-n` were found and returned.\n",
    "narray = np.array([x for x in range(1, n+1)])\n",
    "SDSdf['n Dissimilar'] = narray\n",
    "\n",
    "# Save SDS results.\n",
    "SDSdf.to_csv(f'SDS/SDS_N{len(df)}_{n}_dissimilar.csv', index=False)\n",
    "\n",
    "# Get end timestamp.\n",
    "end = (time()-start)/60    \n",
    "print(end, ' min')\n",
    "\n",
    "# Save final time and summed dissimilarity for benchmarking.\n",
    "if args.bench == True:\n",
    "    idx = SDSdf['matrix index'].values\n",
    "\n",
    "    df.columns = df.columns.astype(int)\n",
    "    submtrx = df[idx].loc[idx]\n",
    "    submtrx = submtrx.applymap(log)\n",
    "    final_sum = submtrx.sum().sum()/2\n",
    "\n",
    "    with open(f'SDS-N{len(df)}-n{n}.txt', 'w') as f:\n",
    "        f.write(f'Total dissimiarity between items of the {n}th set:  {final_sum} \\n')\n",
    "        f.write(f'{end} min')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
